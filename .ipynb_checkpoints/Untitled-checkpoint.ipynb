{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "x = np.loadtxt(\"xtrain.txt\", delimiter=\",\")\n",
    "y = np.loadtxt(\"ytrain.txt\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = int(len(x) * 0.7)\n",
    "\n",
    "xtrain = x[:train_size]\n",
    "ytrain = y[:train_size]\n",
    "\n",
    "xtest = x[train_size:]\n",
    "ytest = y[train_size:]\n",
    "\n",
    "def print_stats(ypre, ytest, scores):\n",
    "    # Get Score:\n",
    "    score = len(filter(lambda x:x[0] == x[1], zip(ypre,ytest)))\n",
    "\n",
    "    nsCorrect = filter(lambda x:x[0] == x[1] and x[0] == 1 , zip(ypre,ytest))\n",
    "#     print('# of true positives: %s'% len(nsCorrect))\n",
    "    nsPred = filter(lambda x: x==1, ypre)\n",
    "#     print('# predicted positives: %s'% len(nsPred))\n",
    "\n",
    "    nsActual = filter(lambda x: x==1, ytest)\n",
    "#     print 'Number of actual No-Shows: %s' %len(nsActual)\n",
    "    print 'Accuracy: %s' % (score*1.0/len(ytest))\n",
    "    print('PPV: %s'%(len(nsCorrect)*1.0/len(nsPred))) # TP / (TP+FP)\n",
    "    print 'Sensitivity or TPR : %s' % (len(nsCorrect)*1.0/(len(nsActual))) #TP / P\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(ytest, scores)\n",
    "    print 'AUROC: %s' % roc_auc_score(ytest, scores)\n",
    "#     print('FPR: %s' % fpr)\n",
    "#     print('TPR: %s' % tpr)\n",
    "#     print('Thresholds: %s' % thresholds)\n",
    "\n",
    "#     print 'PPV: %s' %(len(nsCorrect) * 1.0/ len(nsActual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import izip\n",
    "\n",
    "def plotRocStats(ytest, scores):\n",
    "    fpr, tpr, thresholds = roc_curve(ytest, scores)\n",
    "    \n",
    "    # ROC\n",
    "    plt.figure(0)\n",
    "    plt.clf()\n",
    "    random,= plt.plot(np.arange(0,1,0.001),np.arange(0,1,0.001), label=\"Random\")\n",
    "    plt.title('ROC')\n",
    "    model, = plt.plot(fpr,tpr, label=\"Model\")\n",
    "#     plt.legend(handles=[model,random],loc=4)\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    \n",
    "    # Metrics vs Threshold\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    plt.title('Metrics V.S. Threshold ')\n",
    "    tpr_plot, = plt.plot(thresholds, tpr, label='TPR')\n",
    "    fpr_plot, = plt.plot(thresholds, fpr, label='FPR')\n",
    "    plt.ylabel(\"Percentage\")\n",
    "    plt.xlabel(\"Thresholds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAcc(ytest, scores, th):\n",
    "    accs = []\n",
    "    data_length = len(ytest)\n",
    "    \n",
    "    # Accuracy\n",
    "    for t in th:\n",
    "        acc = 0\n",
    "        for score, y in izip(scores,ytest):\n",
    "            p = 0 if score <= t else 1\n",
    "            if p == y:\n",
    "               acc += 1    \n",
    "        accs.append(acc*1.0 / data_length)\n",
    "    acc_plot, = plt.plot(th, accs, label='Accuracy')\n",
    "    \n",
    "#     plt.legend(handles=[tpr_plot, fpr_plot, acc_plot],loc=5)\n",
    "    plt.ylabel(\"Percentage\")\n",
    "    plt.xlabel(\"Thresholds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ C =  0.01 ------------\n",
      "Accuracy: 0.859574668003\n",
      "PPV: 0.832635983264\n",
      "Sensitivity or TPR : 0.0218058294981\n",
      "AUROC: 0.688015584165\n",
      "FPR: [  0.00000000e+00   0.00000000e+00   1.82715147e-05 ...,   9.99744199e-01\n",
      "   9.99780742e-01   1.00000000e+00]\n",
      "TPR: [  1.09577033e-04   2.73942582e-03   2.73942582e-03 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "Thresholds: [ 0.84720783  0.4217997   0.41993698 ..., -1.66054504 -1.66456957\n",
      " -1.73388968]\n",
      "------------ C =  0.1 ------------\n",
      "Accuracy: 0.859731270358\n",
      "PPV: 0.802867383513\n",
      "Sensitivity or TPR : 0.0245452553145\n",
      "AUROC: 0.689884961735\n",
      "FPR: [  0.00000000e+00   0.00000000e+00   1.82715147e-05 ...,   9.99725927e-01\n",
      "   9.99762470e-01   1.00000000e+00]\n",
      "TPR: [  1.09577033e-04   3.94477318e-03   3.94477318e-03 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "Thresholds: [ 1.51420336  0.82558236  0.81404019 ..., -2.39832364 -2.40084969\n",
      " -2.5172752 ]\n",
      "------------ C =  0.3 ------------\n",
      "Accuracy: 0.859684289652\n",
      "PPV: 0.780405405405\n",
      "Sensitivity or TPR : 0.0253122945431\n",
      "AUROC: 0.68998432686\n",
      "FPR: [  0.00000000e+00   0.00000000e+00   1.82715147e-05 ...,   9.99762470e-01\n",
      "   9.99799013e-01   1.00000000e+00]\n",
      "TPR: [  1.09577033e-04   4.49265834e-03   4.49265834e-03 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "Thresholds: [ 1.68528421  0.88563599  0.87374969 ..., -2.75283091 -2.75546537\n",
      " -2.87260772]\n",
      "------------ C =  0.5 ------------\n",
      "Accuracy: 0.859590328239\n",
      "PPV: 0.75974025974\n",
      "Sensitivity or TPR : 0.025641025641\n",
      "AUROC: 0.689969850399\n",
      "FPR: [  0.00000000e+00   0.00000000e+00   5.48145441e-05 ...,   9.99762470e-01\n",
      "   9.99799013e-01   1.00000000e+00]\n",
      "TPR: [  1.09577033e-04   4.49265834e-03   4.49265834e-03 ...,   1.00000000e+00\n",
      "   1.00000000e+00   1.00000000e+00]\n",
      "Thresholds: [ 1.75133099  0.91489758  0.90341495 ..., -2.89775244 -2.90040663\n",
      " -3.01772046]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# clf = svm.SVC(kernel='linear', C = 1.0)\n",
    "for c in [0.01, 0.1, 0.3, 0.5]:\n",
    "    print \"------------ C =  %s ------------\" % c\n",
    "    clf = svm.LinearSVC(dual=False, C = c)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "\n",
    "    # Predict\n",
    "    ypre = clf.predict(xtest)\n",
    "\n",
    "    # Get Score\n",
    "#     score = len(filter(lambda x:x[0] == x[1], zip(ypre,ytest)))\n",
    "\n",
    "    print_stats(ypre, ytest, clf.decision_function(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "clf = clf.fit(xtrain, ytrain)\n",
    "\n",
    "# Predict\n",
    "ypre = clf.predict(xtest)\n",
    "print_stats(ypre, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ C =  1 ------------\n",
      "Accuracy: 0.839012778752\n",
      "PPV: 0.31589023612\n",
      "Sensitivity or TPR : 0.108481262327\n",
      "AUROC: 0.534653567396\n",
      "------------ C =  3 ------------\n",
      "Accuracy: 0.840954647958\n",
      "PPV: 0.316071428571\n",
      "Sensitivity or TPR : 0.0969756738988\n",
      "AUROC: 0.552016313503\n",
      "------------ C =  5 ------------\n",
      "Accuracy: 0.844681784014\n",
      "PPV: 0.340579710145\n",
      "Sensitivity or TPR : 0.0927021696252\n",
      "AUROC: 0.557288037916\n",
      "------------ C =  7 ------------\n",
      "Accuracy: 0.844901027311\n",
      "PPV: 0.338990066225\n",
      "Sensitivity or TPR : 0.0897435897436\n",
      "AUROC: 0.564608651624\n",
      "------------ C =  10 ------------\n",
      "Accuracy: 0.845871961914\n",
      "PPV: 0.345155709343\n",
      "Sensitivity or TPR : 0.0874424720579\n",
      "AUROC: 0.569517391355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, DecisionTreeClassifier\n",
    "# Create and fit an AdaBoosted decision tree\n",
    "for c in [1, 3, 5, 7, 10]:\n",
    "    print \"------------ C =  %s ------------\" % c\n",
    "    bdt = AdaBoostClassifier(RandomForestClassifier(),algorithm=\"SAMME\", n_estimators=c)\n",
    "    bdt.fit(xtrain, ytrain)\n",
    "\n",
    "    ypre = bdt.predict(xtest)\n",
    "    scores = bdt.decision_function(xtest)\n",
    "    print_stats(ypre, ytest, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC as Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdt = AdaBoostClassifier(svm.SVC(probability=True,kernel='linear'),n_estimators=5, learning_rate=1.0, algorithm='SAMME')\n",
    "ypre = bdt.predict(xtest)\n",
    "scores = bdt.decision_function(xtest)\n",
    "print_stats(ypre, ytest, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier as Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ C =  5 ------------\n",
      "Accuracy: 0.856286018542\n",
      "PPV: 0.480459770115\n",
      "Sensitivity or TPR : 0.068704799474\n",
      "AUROC: 0.702591358675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for c in [ 5]:\n",
    "    print \"------------ C =  %s ------------\" % c\n",
    "    bdt = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=c),\n",
    "        n_estimators=15)\n",
    "    bdt.fit(xtrain, ytrain)\n",
    "    ypre = bdt.predict(xtest)\n",
    "    scores = bdt.decision_function(xtest)\n",
    "    print_stats(ypre, ytest, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "   max_depth=1, random_state=0).fit(xtrain, ytrain)\n",
    "ypre = clf.predict(xtest)\n",
    "\n",
    "print_stats(ypre, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xg_train = xgb.DMatrix(xtrain, label=ytrain)\n",
    "xg_test = xgb.DMatrix(xtest, label=ytest)\n",
    "\n",
    "## setup parameters for xgboost\n",
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 15\n",
    "param['silent'] = 1\n",
    "# param['nthread'] = 4 # comment to use max num of threads\n",
    "param['eval_metric'] ='auc'\n",
    "param['scale_pos_weight'] = 47747*1.0/7836 # scaled by calculating ratio of pos to neg\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 50\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "\n",
    "\n",
    "### get prediction\n",
    "pred = bst.predict( xg_test )\n",
    "print_stats(ytest, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage of no shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = len(filter(lambda x:x == -1, ytest))\n",
    "    \n",
    "print score*1.0/len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
